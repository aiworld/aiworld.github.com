<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>ai world - Mission</title>

    <!-- Bootstrap -->
    <link href="vendor/css/bootstrap.min.css" rel="stylesheet">
    <link href="vendor/css/docs.css" rel="stylesheet">
    <link href="assets/css/aiworld.css" rel="stylesheet">
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,300' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="vendor/jquery.qtip.custom/jquery.qtip.min.css" />

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
</head>
<body>
<!-- Docs page layout -->
<header class="navbar navbar-static-top bs-docs-nav" id="top" role="banner">
  <div class="container">
    <div class="navbar-header">
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target=".bs-navbar-collapse">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a href="index.html" class="navbar-brand">ai world</a>
    </div>
    <!--<nav class="collapse navbar-collapse bs-navbar-collapse" role="navigation">-->
      <!--<ul class="nav navbar-nav">-->
        <!--<li>-->
          <!--<a href="../getting-started/">Getting started</a>-->
        <!--</li>-->
        <!--<li>-->
          <!--<a href="../css/">CSS</a>-->
        <!--</li>-->
        <!--<li>-->
          <!--<a href="../components/">Components</a>-->
        <!--</li>-->
        <!--<li>-->
          <!--<a href="../javascript/">JavaScript</a>-->
        <!--</li>-->
        <!--<li>-->
          <!--<a href="../customize/">Customize</a>-->
        <!--</li>-->
      <!--</ul>-->
      <!--<ul class="nav navbar-nav navbar-right">-->
        <!--<li><a href="http://expo.getbootstrap.com" onclick="ga('send', 'event', 'Navbar', 'Community links', 'Expo');">Expo</a></li>-->
        <!--<li><a href="http://blog.getbootstrap.com" onclick="ga('send', 'event', 'Navbar', 'Community links', 'Blog');">Blog</a></li>-->
      <!--</ul>-->
    <!--</nav>-->
  </div>
</header>

<div class="container bs-docs-container why-body">
    <h1>Why AiWorld?</h1>
    <p>
        Artificial intelligence is on the horizon
        and will do more to change life on earth than
        anything else in our history.
        Intelligence greater than our own
        has the power to solve our most difficult problems,
        but it could become our greatest threat if we don't plan for it
        appropriately.
        AiWorld's mission is to help alleviate this threat
        and realize the monumental benefit AI can offer us as
        in the coming years.
    </p>
    <h2>The Countdown to AI</h2>
    <p>
        <span class="text tianhe-brain">
            So how close are we to actually developing AI?
            By one measure,
            FLOPS or floating-point-operations-per-second,
            the world's most powerful computer, Tianhe-2,
            is already 339 times more powerful than the human brain.
        </span>
        <span class="footnote tianhe-brain">
            Human brains have ~500 terraconnections with 2% active at a time,
            firing at ~100hz and ~1 byte per connection yielding ~100e12
            FLOPS compared to Tianhe-2's 33.89e15 FLOPS.
        </span>
        <span class="text oh-yeah-gpu"><span class="text enceph">
            This is surprising to most,
            since a new laptop in 2015 is 33,000 times
            less powerful and has only 1% of
            the operations per second of the average reptile.
        </span></span>
        <span class="footnote oh-yeah-gpu">
            This is based off the laptop's GPU.
            It's CPU, on which most programs run, performs
            10 to 100 times less FLOPS than that.
        </span>
        <span class="footnote enceph">
            Mean encephalization quotient
            for reptiles is about one tenth of
            that of mammals -
            <a href="http://en.wikipedia.org/wiki/Encephalization_quotient"
            >Encephalization Quotient - Wikipedia</a>
        </span>
        But while there's much more to our brain than operations per second,
        it's clear that the opportunity
        to create human level AI is becoming more tangible,
        especially to groups with access to the world's most powerful computers
        like Tianhe-2.
        Larry Page puts it this way:
    </p>
    <blockquote class="text l-wise">
            There's a 5% chance [AI] will happen every year...mostly based on
            whether anybody's working on it.
        <span class="footnote l-wise">
            <a href="http://youtu.be/8_3OCq_vTWM?t=46m3s"
                    >Larry Page speaks at the AAAS [video]</a> - 2007
        </span>
    </blockquote>
    <p>
        With hardware capability doubling every year, more and more folks
        will have a shot at making that 5% prediction become a reality.
        <span class="text big-spenders">
            For example, assuming the first AI is one million times less
            efficient than our brain and costs
            <span class="text big-buffer">
                $10B (or about the price of 20 Tianhe-2's)
            </span><span class="footnote big-buffer">
            Why $10B when Tianhe-2 for $400M already has 339 times more
            FLOPS than our brain?
            1) To make up for inefficiencies in design compared to our brain.
            2) To allow for more than one simultaneous experiment.
            3) Environment simulation.
            4) Other bottlenecks (besides FLOPS) like memory, bandwidth,
            write speed, connectivity, training, algorithms, etc...
            </span> <<
            more than two-hundred companies,
            governments, and individuals could already make that purchase today.
        </span>
        <span class="footnote big-spenders">
            <a href="http://issuu.com/wsj.com/docs/corpcash.pdf"
                    >24 companies</a>
            and
            <a href="http://data.worldbank.org/indicator/FI.RES.TOTL.CD"
                    >70 governments</a>
            have $10B in cash reserves while
            <a href="http://www.forbes.com/billionaires/list"
                >123 individuals</a> have that in net worth.
        </span>
        <span class="text l-wise2"><span class="text time-to-semi-cheap">
            And the same hardware in 2050 will be just $1M -
            giving most businesses, all governments,
            and millions of individuals access
            to said mind blowing computational power.
        </span></span>
        <span class="footnote time-to-semi-cheap">
            Based of Moore's law -
            ($10B is 10,000 or 1E4 times $1M. And 1E4x ~= 2^13x or 13 doublings.
            So with a 2 year doubling time this would be about 26 years from
            2014 -> 2050)
        </span>
        <span class="footnote l-wise2">
            Also, the design complexity of our brain is large but not
            unprecedented, since our DNA is about
            <a href="https://www.biostars.org/p/5514/">1GB compressed</a>
            - roughly the same size as a
            <a href="http://askubuntu.com/questions/430040/what-is-the-file-size-of-the-ubuntu-iso-image">
                modern operating system.</a>
        </span>
    </p>
    <p>
        Another way to approximate the timeframe in which AI
        will be developed is to base it off a
        fully functioning artificial neural net today.
        <span class="text big-ol-net">
            For example, the world's largest neural net has
            hundreds of billions of connections
        </span>
        whereas the human brain has about 100k times
        that.<span class="footnote big-ol-net">
            Ren Wu1, Shengen Yan, Yi Shan, Qingqing Dang, Gang Sun -
            Baidu Research -
            <a href="http://arxiv.org/pdf/1501.02876v1.pdf"
                    >Deep Image: Scaling up Image Recognition</a>
            - 2015.
        </span>
        <span class="text text its-a-range"><span class="text wow-nn"><span class="text conn-growth">
            So - given a conservative two year doubling time in connectivity,
            a human sized neural net could be available
            by 2050.
            However, current connectivity growth is much higher than that,
            increasing by an order of magnitude almost every year,
            and if that amazing pace keeps up, we could see human sized nets by
            2020.
        </span></span></span>
        <span class="footnote conn-growth">
            Doubling time in neural net size is currently much less than
            two years, driven mainly by software.
            These improvements involve seamless coordination of
            several computers to form one neural net by
            1. splitting the net into overlapping subnets (aka model parallelism),
            2. training several inputs in parallel (aka data parallelism), and
            3. <a href="http://youtu.be/EK61htlw8hY?t=34m51s"
                    >compressing large nets into smaller ones.</a>
            For example, the largest artificial neural net consisted of one
            billion connections in 2012
            <a href="http://research.google.com/pubs/pub38115.html"
                    >at Google</a> and used CPU's on 1,000 machines.
            Model parallelism on GPU's was made possible with more
            efficient neural net connection matrix calcuations
            and using Infiniband to connect GPU's across machines.
            This achieved a net with
            10x more connections on just three machines
            <a href="http://www.cs.stanford.edu/~acoates/papers/CoatesHuvalWangWuNgCatanzaro_icml2013.pdf"
                    >in 2013.</a>
            Data parallelism and model compression have more recently been
            used to achieve faster training times on large nets doing
            voice recognition at Google and Microsoft using a technique called
            HOGWILD aka "lazy updates". The latest jump to 100B connections
            involved scaling to a much larger cluster of GPU's again
            through optimizing software to run efficiently across several
            machines, with high CPU neural layers (convolutional layers)
            distributed across different machines than high memory
            (fully connected) layers.
        </span>
        <span class="footnote wow-nn">
            Practical performance of neural nets is also following exponential
            trends in contests like ImageNet where 2012 saw
            <a href="http://arxiv.org/abs/1409.0575"
                    >15% error, 2013 - 11% error, and 2014 - 6% error.</a>
            Basically, there is marginal difference between humans
            and computers now on this 1,000 category classification task today.
            (To see the errors the 2014 model made, check out
            <a href="http://cs.stanford.edu/people/karpathy/ilsvrc/">this</a>
            and
            <a href="http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/">this.</a>
            TL;DR - They aren't egregious!)
        </span>
        <span class="footnote its-a-range">
            Doubling times of one to three years are typical
            <a href="http://youtu.be/RIkxVci-R4k?t=7m47s">among
            information technologies</a>.
        </span>
    </p>
    <p>
        Another common view is that AI will emerge through mirroring the
        human brain's connections in-silica.
        <span class="text blue-brain"><span class="text biowesome">
            The Blue Brain project is trying to do just that and
            are on track to reach their goal of simulating every neuron
            in the brain by 2023.
        </span></span>
        <span class="footnote blue-brain">
            10,000 neurons were simulated by The Blue Brain Project in 2008.
            This increased 100x to 1M neurons in 2011. -
            <a href="http://en.wikipedia.org/wiki/Blue_Brain_Project"
                    >Blue Brain</a> - Wikipedia.
        </span>
        <span class="footnote biowesome">
            Other extremely interesting projects such as
            <a href="eyewire.org">Eyewire</a>
            and
            <a href="http://www.openworm.org/">OpenWorm</a>
            show deep insights into working biological systems.
            For example, Eyewire has already made an
            <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.scientificamerican.com%2Farticle%2Fonline-gamers-help-crack-mystery-of-how-eyes-sense-motion%2F&sa=D&sntz=1&usg=AFQjCNHUDVa04CORARUIUd09GyVcIyTo2Q"
                    >important discovery
            into how our eyes detect motion</a> and
            OpenWorm shows us how a small number of neurons connected in a
            highly recursive way can achieve amazing results.
            <a href="http://www.i-programmer.info/news/105-artificial-intelligence/7985-a-worms-mind-in-a-lego-body.html"
                    >See this embodiment of OpenWorm in a robot</a> and the
            <a href="https://news.ycombinator.com/item?id=8745639"
                    >engineer's comments on Hacker News</a>.
        </span>
    </p>
    <p>
        <span class="text bostrom-survey">
            Nick Bostrom has also released a survey
            of 170 AI experts in 2014 asking when
            machines will replace every human job.
            The results: 10% predict it will happen by
            by 2022, with 40% by 2040, and 90% by 2075.
        </span>
        <span class="footnote bostrom-survey">
            Nick Bostrom -
            <a href="http://www.nickbostrom.com/papers/survey.pdf"
                    >Future Progress in Artificial Intelligence: A Survey of Expert Opinion</a>
            - 2014
        </span>
    </p>
    <p>
        <span class="text kurzweil">
            Not to mention the most prolific predictor of AI, Ray Kurzweil,
            who puts the date of full brain emulation at 2035 and
            then ten years later, predicts "The Singularity"
            where machines create their successors and ignite
            an intelligence explosion in 2045.
        </span>

        <span class="footnote kurzweil">
            Ray Kurzweil -
            <a href="http://en.wikipedia.org/wiki/The_Singularity_Is_Near"
                    >The Singulariy is Near</a> - 2005
        </span>
    </p>
    <p>
        A more concrete glimpse into one of the most promising AI efforts,
        DeepMind, was recently provided by Elon Musk, the
        engineer & entrepreneur behind PayPal, Solar City, Tesla, and SpaceX
        who said
    </p>
    <blockquote class="text musk">
        <p>The pace of progress in artificial general intelligence (I'm not
            referring to narrow AI) is incredibly fast. Unless
            you have direct exposure to groups like Deepmind, you have no idea
            how fast - it is growing at a pace
            close to exponential. The risk of something seriously dangerous
            happening is in the five year timeframe, 10
            years at most. Please note that I am normally super pro technology,
            and have never raised this issue until
            recent months. This is not a case of crying wolf about something I
            don't understand.
        </p>

        <p>
            I am not alone in thinking we should be worried. The leading AI
            companies have taken great steps to
            ensure safety. They recognize the danger, but believe that they can
            shape and control the digital
            superintelligences and prevent bad ones from escaping into the
            Internet. That remains to be seen...
        </p>
        <span class="footnote musk">
            Elon Musk's
            <a href="http://i.imgur.com/sL0uqqW.jpg">deleted comment</a>
            from
            <a href="http://edge.org/conversation/the-myth-of-ai"
                    >The Myth of AI</a>, The Edge - 2014
        </span>
    </blockquote>
    <p>
        <span class="text luddite">
            Given the imminence of such metamorphic change,
            it seems that we should be employing everything we know,
            allocating every possible resource, and
            focusing our brightest minds on making the transition to beyond
            human AI go as well as possible.
        </span>
        <span class="footnote luddite">
            Also, preventing the transition is unlikely since those
            who embrace AI will achieve significant advantage
            over those who don't.
            In addition Peter Thiel argues in
            <a href="http://zerotoonebook.com/"><i>Zero to One</i></a> that
            stagnation will lead to armegeddon over entrenched conflict
            for unchanging resources. Avoiding such stagnation without AI
            may be possible as a spacefaring civilization,
            also avoiding problems like global warming,
            but this again is highly unlikely due to the massive power and draw
            of AI.
        </span>
        As Stephan Hawking said:
    </p>
    <blockquote class="text futureoflife">
        The potential benefits are huge; everything that civilisation has to
        offer is a product of human intelligence; we cannot predict what we
        might achieve when this intelligence is magnified by the tools that AI
        may provide, but the eradication of war, disease, and poverty would be
        high on anyone's list. Success in creating AI would be the biggest event
        in human history.
        Unfortunately, it might also be the last,
        unless we learn how to avoid the risks.
        <span class="footnote futureoflife">
            Stephen Hawking, Stuart Russel, Max Tegmark, Frank Wilcek -
            <a href="http://www.independent.co.uk/news/science/stephen-hawking-transcendence-looks-at-the-implications-of-artificial-intelligence--but-are-we-taking-ai-seriously-enough-9313474.html">
                Stephen Hawking: 'Transcendence looks at the implications of artificial intelligence - but are we taking AI seriously enough?'
            </a> - The Independent
        </span>
    </blockquote>
    <h2>How</h2>
    <p>
        <span class="text cev">
            AiWorld's goal is to safely facilitate a path to AI by
            crowdsourcing the training of AI  -
            to allow society
            to teach AI the difference between right and wrong, first at
            basic / functional levels, then working towards higher
            moral and ethical types of behavior.
            There are several synergies to this approach which lead to
            better AI in the short term and give more influence
            and transparency into AI
            over the long term.
        </span>
        <span class="footnote cev">
            This aligns in spirit with Eliezer Yudkowsky's
            <a href="http://intelligence.org/files/CEV.pdf"
                    >coherent extrapolated volition</a> or CEV, where
            society's average will dictates
            the behavior of AI. However, in reality,
            the groups that choose to participate in AiWorld
            would determine the behavior of AI. The independence of such
            groups would additionally provide a distribution of power or
            <a href="http://en.wikipedia.org/wiki/Evaluative_diversity"
                    >"evaluative diversity"</a> in the AI's produced.
        </span>
        These synergies are crucial because
        <b>safe AI must be first to matter</b>.
    </p>
    <p>
        <span class="text breakthroughs">
            Creating the breakthroughs necessary for human level AI will
            likely require the work of many small, autonomous
            teams.
        </span>
        <span class="footnote breakthroughs">
            Historic breakthroughs by small teams include
            three axis control for manned flight, Page Rank,
            the light bulb, Newtonâ€™s laws, general relativity, and countless
            more.
        </span>
        <span class="text infra">
            However, given the scope
            of the work, it makes sense to have
            to have a platform where these teams can cooperate,
            breakthroughs can be disseminated,
            and AI's can be compared using benchmarks
            aligned towards the goal of beneficial AI.
        </span>
        <span class="footnote infra">
            AI that moves quickly from breakthroughs to applications
            will create financial incentives for further breakthroughs.
            AiWorld will attempt to facilitate this by allowing small teams
            to showcase their results on practically applicable datasets.
        </span>
        Creating datasets and training AI is one of those laborious
        tasks that small teams of experts have neither the time
        nor the interest to pursue.
        However, providing the 'nurture' side
        of the nature / nurture equation is a vital role
        that AiWorld seeks to facilitate by paying anyone who can play a
        videogame to help train and create high quality datasets for AI's to
        learn from.
    </p>

    <!--
        Encapsulate moral growth
        Defend humans, the future of humanity, and humane nature.
        Keey humankind ultimately in charge of its own destiny.
    -->
    <h3>The role of emotional intelligence</h3>
    <p>
        <span class="text symbol-grounding">
            Everything we know is built on an innately human experience,
            and fundamental to that experience are our emotions.
            Without emotions, machines will be far less adept at
            learning from the vast knowledge base we have created
            and researchers will be forced to create artificial ways
            for machines to understand humans.
            One can draw a relation to the symbol grounding problem
        </span>
        where it is theorized that words are best understood via a grounding
        in the images, sounds, and other aspects of the human experience
        from which they have been made to abstract.
        <span class="footnote symbol-grounding">
            <a href="http://en.wikipedia.org/wiki/Symbol_grounding"
                >Symbol Grounding</a> - Wikipedia
        </span>
        Similarly, it would be very hard for a computer to answer the
        following question without a solid grounding
        in the human emotional experience:
    </p>
    <blockquote class="text winograd">
        Frank was jealous when Bill said that he was the winner of the
        competition. Who was the winner?
    </blockquote>
    <p>
        For a computer to extract the correct answer
        from just the text would be, if not impossible, extremely difficult
        at this time.
        <span class="footnote winograd">
            Such "Winograd schema questions" are examples of
            frontiers in AI, for many of which solutions are yet undiscovered -
            <a href="http://www.cs.toronto.edu/~hector/Papers/ijcai-13-paper.pdf"
                   >On our best behaviour</a> - Hector Levesque - 2013
        </span>
        However, if we program AI to learn like we do,
        via an embodied and emotional experience - then it
        would not only know the correct answer but it would have a visceral
        understanding of the feeling the answer describes.
        <span class="text deepimagesent">
            Even the amazing results that have been achieved in symbol grounding,
            such as Stanford's DeepImageSent
        </span>
        <span class="footnote deepimagesent">
            <a href="https://cs.stanford.edu/people/karpathy/deepimagesent"
                    >Deep Visual-Semantic Alignments for Generating Image
                Descriptions</a> -
            Andrej Karpathy, Li Fei-Fei - 2014
        </span>
        <span class="text really-far">
            would need human experience and emotion
            to understand the images the way humans do.
        </span>
        <span class="footnote really-far">
          Andrej Karpathy -
          <a href="http://karpathy.ca/myblog/?p=292"
            >The state of Computer Vision and AI: we are really, really far.</a>
            - 2012
        </span>
        Because without emotions,
        AI will be like a rain man / idiot savant -
        really good at some things, but
        maladjusted in its ability to plugin to our world as a whole.
    </p>
    <p>
        Take the following quote from Yann Lecun, one of the world's preeminent
        AI researchers:
    </p>
    <blockquote class="text yann">
        I think emotions are an integral part of intelligence.
        Science fiction often depicts AI systems as devoid of emotions,
        but I don't think real AI is possible without emotions.
        Emotions are often the result of predicting a likely outcome.
        For example,
        fear comes when we are predicting that something bad (or unknown)
        is going to happen to us. Love is an emotion that evolution built
        into us because we are social animals and we need to reproduce and
        take care of each other. Future AI systems that interact with humans
        will have to have these emotions too.
        <span class="footnote yann">
            Yann Lecun -
            <a href="http://www.reddit.com/r/MachineLearning/comments/25lnbt/ama_yann_lecun/chiftyb"
                    >Reddit AMA</a> - 2014
        </span>
    </blockquote>
    <p>
        <span class="text robot-emotion">
            The only way we know how to create moral beings is the way we
            teach our children and emotions are a fundamental to that.
            Without emotion, we would be inept at judging the values of our actions,
            unable to learn from each other,
            and incapable of maintaining the relationships we rely on to function
            as a society.
        </span>
        <span class="footnote robot-emotion">
            Breazeal, Brooks -
            <a href="http://web.media.mit.edu/~cynthiab/Papers/Breazeal-Brooks-03.pdf"
                >Robot Emotion: A Functional Perspective</a>
            - 2003
        </span>
        Why then should artificial intelligence be devoid
        of emotions? It most certainly should not!
    </p>
    <p>
        One seminal work on the potential of machine intelligence
        came from mathematician and early computing pioneer I. J. Good in
        1965.
    </p>
    <p>
        In it, Good not only first describes the Singularity,
        but is prescient about developments leading to it, saying
    </p>
    <blockquote class="text ij">
        Economy is important in any engineering venture, but especially so
        when the price is exceedingly high, as it most likely will be for the
        first ultraintelligent machine. Hence
        semantics is relevant to the design of such a machine.
        Yet a detailed knowledge of semantics might not be required,
        since the artificial neural network will largely take care of it,
        provided that the parameters are correctly chosen,
        and provided that the network is adequately integrated with
        its sensorium and motorium (input and output).
        For, if these conditions are met,
        the machine will be able to learn from experience, by
        means of positive and negative reinforcement,
        and the instruction of the machine will resemble that of a
        child.
        <span class="footnote ij">
            Irving John Good -
            <a href="http://webdocs.cs.ualberta.ca/~sutton/Good65ultraintelligent.pdf"
                >Speculations Concerning the First Ultraintelligent Machine</a>
            - 1965
        </span>
    </blockquote>
    <p>
        Good amazingly described artificial neural nets,
        reinforcement learning, and feature learning in 1965 -
        long before they rose to prominence in the fields of AI and robotics.
        I believe his last statement describes the idea behind AiWorld.
    <blockquote>
        ...the instruction of the machine will resemble that of a child.
    </blockquote>

    <p>
        A crowdsourced AI training platform
        allows our intelligence, including emotion,
        to be transmitted via interaction with real people as is done
        in our own childhood.
        It provides a decentralized, transparent, and
        iterative way to pursue more sophisticated intelligences, and
        allows us to mold AI in the way we think is best as a society.
    </p>
    <p>
        Let's make AI the vehicle to the future we want for each other, together.
    </p>
    <h2>What can you do?</h2>
    <ul class="call-to-action">
      <li>If you are passionate about working on this, please contact me at craig<span></span>@aiworld.io
      <li><a href="https://vivid-fire-9851.firebaseapp.com/">Help train artificial intelligence</a>
      <li><a href="http://eepurl.com/bcn4Vr">Join the mailing list</a>
      <li>Donate


    </ul>
    <h3>
        Footnotes
    </h3>
    <ol class="footnotes"></ol>
    <h4 class="sig">
        Craig Quiter - 1/4/2015
    </h4>
</div>
<!-- Placed at the end of the document so the pages load faster -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
<script src="vendor/js/bootstrap.min.js"></script>
<script src="vendor/js/docs.js"></script>
<script src="vendor/js/d3.min.js"></script>
<script src="vendor/jquery.qtip.custom/jquery.qtip.min.js"></script>
<script src="assets/js/main.js"></script>
<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
<script src="vendor/js/ie10-viewport-bug-workaround.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-3213633-17', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>