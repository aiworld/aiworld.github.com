<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>ai world - Mission</title>

    <!-- Bootstrap -->
    <link href="vendor/css/bootstrap.min.css" rel="stylesheet">
    <link href="vendor/css/docs.css" rel="stylesheet">
    <link href="assets/css/aiworld.css" rel="stylesheet">
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,300' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="vendor/jquery.qtip.custom/jquery.qtip.min.css" />

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
</head>
<body>
<!-- Docs page layout -->
<header class="navbar navbar-static-top bs-docs-nav" id="top" role="banner">
  <div class="container">
    <div class="navbar-header">
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target=".bs-navbar-collapse">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a href="index.html" class="navbar-brand">ai world</a>
    </div>
    <!--<nav class="collapse navbar-collapse bs-navbar-collapse" role="navigation">-->
      <!--<ul class="nav navbar-nav">-->
        <!--<li>-->
          <!--<a href="../getting-started/">Getting started</a>-->
        <!--</li>-->
        <!--<li>-->
          <!--<a href="../css/">CSS</a>-->
        <!--</li>-->
        <!--<li>-->
          <!--<a href="../components/">Components</a>-->
        <!--</li>-->
        <!--<li>-->
          <!--<a href="../javascript/">JavaScript</a>-->
        <!--</li>-->
        <!--<li>-->
          <!--<a href="../customize/">Customize</a>-->
        <!--</li>-->
      <!--</ul>-->
      <!--<ul class="nav navbar-nav navbar-right">-->
        <!--<li><a href="http://expo.getbootstrap.com" onclick="ga('send', 'event', 'Navbar', 'Community links', 'Expo');">Expo</a></li>-->
        <!--<li><a href="http://blog.getbootstrap.com" onclick="ga('send', 'event', 'Navbar', 'Community links', 'Blog');">Blog</a></li>-->
      <!--</ul>-->
    <!--</nav>-->
  </div>
</header>

<div class="container bs-docs-container why-body">
    <h1>Why AiWorld?</h1>
    <p>
        Artificial intelligence is the single most important pursuit
        our civilization has ever undertaken.
        An intelligence creating one greater than itself is
        the most transformational process we know of
        and yet one still only achieved by evolution
        over millions of years.
        Computers are only now starting to understand us, and we to
        understand them. The possibilities are endless, and the partnership
        is flourishing, but many also worry about the potential for
        increasingly
        autonomous machines to be become a major threat and
        act against our best interests.
        AiWorlds's goal is to give society transparency and influence
        into the behavior of AI in order to align what are
        often considered disparate goals:
        the safety and sophistication of AI.
    </p>
    <h2>The State of AI</h2>
    <p>
        Since the advent of computing, we have both
        underestimated[Ai Winter] <i>and</i> overestimated[Dartmouth]
        computers' potential to do things only humans were capable of before.
        [backgammon], [i j good ultraintelligence]
        The question of how close we are to actually developing intelligence
        that can do <i>everything</i> a human can do,
        which for the purposes
        of this document will be simply referred to as AI often called AGI,
        is one I will attempt to survey by taking a look
        at both the fundamental elements necessary for AI
        as well as previous attempts at providing a timeline for the
        development AI.
    </p>
    <p>
        <span class="text tianhe-brain">
            One fundamental measure of raw computation is floating point
            operations per second or FLOPS.
            By this measure, the world's most powerful computer, Tianhe-2,
            is already 339 times more powerful than synapse based
            estimates on the power of the human brain.
        </span>
        <span class="footnote tianhe-brain">
            Human brains have ~500 terraconnections with 2% active at a time,
            firing at ~100hz and ~1 byte per connection yielding ~100e12
            FLOPS compared to Tianhe-2's 33.89e15 FLOPS.
            [Some research suggests one neuron behaves like an entire
            neural net.]
        </span>
        <span class="text oh-yeah-gpu"><span class="text enceph">
            This is surprising to many,
            as a new laptop in 2015 is 33,000 times
            less powerful and has just 1% of
            the operations per second of the average reptile.
        </span></span>
        <span class="footnote oh-yeah-gpu">
            This is based off the laptop's GPU.
            It's CPU, on which most programs run, performs
            10 to 100 times less FLOPS than that.
        </span>
        <span class="footnote enceph">
            Mean encephalization quotient
            for reptiles is about one tenth of
            that of mammals -
            <a href="http://en.wikipedia.org/wiki/Encephalization_quotient"
            >Encephalization Quotient - Wikipedia</a>
        </span>
        Certainly there's much more to our brain than operations per second,
        but it's important to note that this level of computation
        has only recently come online become accessible any group in the last 10
        years, in 2005.
        Also, the fundamental characteristic of information technology
        to improve by factors proportional to its current size
        means that we will very likely see another hundred fold increase
        in next 10 years. Previous incorrect predictions about
        AI involved overestimating the hardware capability [good, kurzweil, vinge]
        that would be available. Today's estimates are less about hardware and
        more about the other elements, namely,
        breakthroughs in machine learning,
        systems software to scale these techniques within reasonable budgets,
        and accumulation of appropriate datasets
        for training.
   </p>
   <p>

      Larry Page puts it this way:

    <blockquote class="text l-wise">
            There's a 5% chance [AI] will happen every year...mostly based on
            whether anybody's working on it.
        <span class="footnote l-wise">
            <a href="http://youtu.be/8_3OCq_vTWM?t=46m3s"
                    >Larry Page speaks at the AAAS [video]</a> - 2007
        </span>
    </blockquote>
    <p>
        With hardware capability doubling every year, more and more folks
        will have a shot at making that 5% prediction become a reality.
        <span class="text big-spenders">
            For example, assuming the first AI is one million times less
            efficient than our brain and costs
            <span class="text big-buffer">
                $10B (or about the price of 20 Tianhe-2's)
            </span><span class="footnote big-buffer">
            Why $10B when Tianhe-2 for $400M already has 339 times more
            FLOPS than our brain?
            1) To make up for inefficiencies in design compared to our brain.
            2) To allow for more than one simultaneous experiment.
            3) Environment simulation.
            4) Other bottlenecks (besides FLOPS) like memory, bandwidth,
            write speed, connectivity, training, algorithms, etc...
            </span> <<
            more than two-hundred companies,
            governments, and individuals could already make that purchase today.
        </span>
        <span class="footnote big-spenders">
            <a href="http://issuu.com/wsj.com/docs/corpcash.pdf"
                    >24 companies</a>
            and
            <a href="http://data.worldbank.org/indicator/FI.RES.TOTL.CD"
                    >70 governments</a>
            have $10B in cash reserves while
            <a href="http://www.forbes.com/billionaires/list"
                >123 individuals</a> have that in net worth.
        </span>
        <span class="text l-wise2"><span class="text time-to-semi-cheap">
            And the same hardware in 2050 will be just $1M -
            giving most businesses, all governments,
            and millions of individuals access
            to said computational power.
        </span></span>
        <span class="footnote time-to-semi-cheap">
            Based of Moore's law -
            ($10B is 10,000 or 1E4 times $1M. And 1E4x ~= 2^13x or 13 doublings.
            So with a 2 year doubling time this would be about 26 years from
            2014 -> 2050)
        </span>
        <span class="footnote l-wise2">
            Also, the design complexity of our brain is large but not
            unprecedented, since our DNA is about
            <a href="https://www.biostars.org/p/5514/">1GB compressed</a>
            - roughly the same size as a
            <a href="http://askubuntu.com/questions/430040/what-is-the-file-size-of-the-ubuntu-iso-image">
                modern operating system.</a>
        </span>
    </p>
    <p>
        Another way to survey the timeframe in which AI
        will be developed is to look at tasks which humans are naturally
        good at, and compare them with machines.
        <span class="text big-ol-net">
            For example, the world's largest neural net has
            hundreds of billions of connections
        </span>
        whereas the human brain has about 100k times
        that.<span class="footnote big-ol-net">
            Ren Wu1, Shengen Yan, Yi Shan, Qingqing Dang, Gang Sun -
            Baidu Research -
            <a href="http://arxiv.org/pdf/1501.02876v1.pdf"
                    >Deep Image: Scaling up Image Recognition</a>
            - 2015.
        </span>
        <span class="text text its-a-range"><span class="text wow-nn"><span class="text conn-growth">
            So - given a conservative two year doubling time in connectivity,
            a human sized neural net could be available
            by 2050.
            However, current connectivity growth is much higher than that,
            increasing by an order of magnitude almost every year,
            and if that amazing pace keeps up, we could see human numbers of connections by
            2020. While connections in these nets are vastly different than
            our own in pattern, substrate, signaling and more, we do
            see similarity in the patterns understood by these nets and
            our own brains [Ng]. However, the number of training examples required
            to learn these patterns [tennenbaum-mit hinton-seconds] is several orders of
            magnitude beyond humans. Also relating the function
            (1000 categories with 100B connections vs the billion categories
            we do with 140E10 1E8 connections / category vs 1E3 connections / category for us roughly)
            we do much more per connection. This only counts recognizing (classification),
            not locating (detection), movement, etc...
        </span></span></span>
        <span class="footnote conn-growth">
            Doubling time in neural net size is currently much less than
            two years, driven mainly by software.
            These improvements involve seamless coordination of
            several computers to form one neural net by
            1. splitting the net into overlapping subnets (aka model parallelism),
            2. training several inputs in parallel (aka data parallelism), and
            3. <a href="http://youtu.be/EK61htlw8hY?t=34m51s"
                    >compressing large nets into smaller ones.</a>
            For example, the largest artificial neural net consisted of one
            billion connections in 2012
            <a href="http://research.google.com/pubs/pub38115.html"
                    >at Google</a> and used CPU's on 1,000 machines.
            Model parallelism on GPU's was made possible with more
            efficient neural net connection matrix calcuations
            and using Infiniband to connect GPU's across machines.
            This achieved a net with
            10x more connections on just three machines
            <a href="http://www.cs.stanford.edu/~acoates/papers/CoatesHuvalWangWuNgCatanzaro_icml2013.pdf"
                    >in 2013.</a>
            Data parallelism and model compression have more recently been
            used to achieve faster training times on large nets doing
            voice recognition at Google and Microsoft using a technique called
            HOGWILD aka "lazy updates". The latest jump to 100B connections
            involved scaling to a much larger cluster of GPU's again
            through optimizing software to run efficiently across several
            machines, with high CPU neural layers (convolutional layers)
            distributed across different machines than high memory
            (fully connected) layers.
        </span>
        <span class="footnote wow-nn">
            Practical performance of neural nets is also following exponential
            trends in contests like ImageNet where 2012 saw
            <a href="http://arxiv.org/abs/1409.0575"
                    >15% error, 2013 - 11% error, and 2014 - 6% error.</a>
            Basically, there is marginal difference between humans
            and computers now on this 1,000 category classification task today.
            (To see the errors the 2014 model made, check out
            <a href="http://cs.stanford.edu/people/karpathy/ilsvrc/">this</a>
            and
            <a href="http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/">this.</a>
            TL;DR - They aren't egregious!)
        </span>
        <span class="footnote its-a-range">
            Doubling times of one to three years are typical
            <a href="http://youtu.be/RIkxVci-R4k?t=7m47s">among
            information technologies</a>.
        </span>
    </p>
    <p>
        Another common view is that AI will emerge through mirroring the
        human brain's connections in-silica.
        <span class="text blue-brain"><span class="text biowesome">
            The Blue Brain project is trying to do just that and
            is on track to reach their goal of simulating every neuron
            in the brain by 2023.
        </span></span>
        <span class="footnote blue-brain">
            10,000 neurons were simulated by The Blue Brain Project in 2008.
            This increased 100x to 1M neurons in 2011. -
            <a href="http://en.wikipedia.org/wiki/Blue_Brain_Project"
                    >Blue Brain</a> - Wikipedia.
        </span>
        <span class="footnote biowesome">
            Other extremely interesting projects such as
            <a href="eyewire.org">Eyewire</a>
            and
            <a href="http://www.openworm.org/">OpenWorm</a>
            show deep insights into working biological systems.
            For example, Eyewire has already made an
            <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.scientificamerican.com%2Farticle%2Fonline-gamers-help-crack-mystery-of-how-eyes-sense-motion%2F&sa=D&sntz=1&usg=AFQjCNHUDVa04CORARUIUd09GyVcIyTo2Q"
                    >important discovery
            into how our eyes detect motion</a> and
            OpenWorm shows us how a small number of neurons connected in a
            highly recursive way can achieve amazing results.
            <a href="http://www.i-programmer.info/news/105-artificial-intelligence/7985-a-worms-mind-in-a-lego-body.html"
                    >See this embodiment of OpenWorm in a robot</a> and the
            <a href="https://news.ycombinator.com/item?id=8745639"
                    >engineer's comments on Hacker News</a>.
        </span>
    </p>
    <p>
        <span class="text bostrom-survey">
            Nick Bostrom has also released a survey
            of 170 AI experts in 2014 asking when
            machines will replace every human job.
            The results: 10% predict it will happen by
            by 2022, with 40% by 2040, and 90% by 2075.
        </span>
        <span class="footnote bostrom-survey">
            Nick Bostrom -
            <a href="http://www.nickbostrom.com/papers/survey.pdf"
                    >Future Progress in Artificial Intelligence: A Survey of Expert Opinion</a>
            - 2014
        </span>
    </p>
    <p>
        <span class="text kurzweil">
            Not to mention the most prolific predictor of AI, Ray Kurzweil,
            who puts the date of full brain emulation at 2035 and
            then ten years later, predicts "The Singularity"
            where machines create their successors and ignite
            an intelligence explosion in 2045.
        </span>

        <span class="footnote kurzweil">
            Ray Kurzweil -
            <a href="http://en.wikipedia.org/wiki/The_Singularity_Is_Near"
                    >The Singulariy is Near</a> - 2005
        </span>
    </p>
    <p>
        A more concrete glimpse into one of the most promising AI efforts,
        DeepMind, was recently provided by Elon Musk, the
        engineer & entrepreneur behind PayPal, Solar City, Tesla, and SpaceX
        who said
    </p>
    <blockquote class="text musk">
        <p>The pace of progress in artificial general intelligence (I'm not
            referring to narrow AI) is incredibly fast. Unless
            you have direct exposure to groups like Deepmind, you have no idea
            how fast - it is growing at a pace
            close to exponential.
        </p>
        <span class="footnote musk">
            Elon Musk's
            <a href="http://i.imgur.com/sL0uqqW.jpg">deleted comment</a>
            from
            <a href="http://edge.org/conversation/the-myth-of-ai"
                    >The Myth of AI</a>, The Edge - 2014
        </span>
    </blockquote>
    <p>
        While DeepMind is doing work that is exponentially getting better
        [compare DQN to newest DQN, HyperNEAT, etc... UTC hybrids],
        they are still operating within Atari and instead of scaling,
        building the fundamental pieces of intelligence (planning, prediction,
        action, memory) required for machines that think like us.
    </p>
    <p>
        <span class="text luddite">
            Given the likelihood of such change happening relatively soon,
            it seems like we should be paying a little more attention to it
            and devoting more resources to it than we are currently.
        </span>
        <span class="footnote luddite">
            Also, preventing the transition is unlikely since those
            who embrace AI will achieve significant advantage
            over those who don't.
            In addition Peter Thiel argues in
            <a href="http://zerotoonebook.com/"><i>Zero to One</i></a> that
            stagnation will lead to armegeddon over entrenched conflict
            for unchanging resources. Avoiding such stagnation without AI
            may be possible as a spacefaring civilization,
            also avoiding problems like global warming,
            but this again is highly unlikely due to the competitive advantage
            of AI.
        </span>
        As Stephan Hawking said:
    </p>
    <h2>How</h2>
    <p>
        <span class="text cev">
            AiWorld's goal is to safely facilitate a path to AI by
            crowdsourcing the training of AI  -
            to allow society
            to teach AI the difference between right and wrong, first at
            basic / functional levels, then working towards higher
            moral and ethical types of behavior.
            There are several synergies to this approach which lead to
            better AI in the short term and give more influence
            and transparency into AI
            over the long term.
        </span>
        <span class="footnote cev">
            This aligns in spirit with Eliezer Yudkowsky's
            <a href="http://intelligence.org/files/CEV.pdf"
                    >coherent extrapolated volition</a> or CEV, where
            society's average will dictates
            the behavior of AI. However, in reality,
            the groups that choose to participate in AiWorld
            would determine the behavior of AI. The independence of such
            groups would additionally provide a distribution of power or
            <a href="http://en.wikipedia.org/wiki/Evaluative_diversity"
                    >"evaluative diversity"</a> in the AI's produced.
        </span>
        These synergies are crucial because
        <b>safe AI must be first to matter</b>.
    </p>
    <p>
        <span class="text breakthroughs">
            Creating the breakthroughs necessary for human level AI will
            likely require the work of many small, autonomous
            teams.
        </span>
        <span class="footnote breakthroughs">
            Historic breakthroughs by small teams include
            three axis control for manned flight, Page Rank,
            the light bulb, Newton’s laws, general relativity, and countless
            more.
        </span>
        <span class="text infra">
            However, given the scope
            of the work, it makes sense to have
            to have a platform where these teams can cooperate,
            breakthroughs can be disseminated,
            and AI's can be compared using benchmarks
            aligned towards the goal of creating beneficial AI.
        </span>
        <span class="footnote infra">
            AI that moves quickly from breakthroughs to applications
            will create financial incentives for further breakthroughs.
            AiWorld will attempt to facilitate this by allowing small teams
            to showcase their results on practically applicable datasets.
        </span>
        Creating datasets and training AI is one of those laborious, yet
        extremely critical [see imagenet crowdsourcing]
        tasks that small teams of experts have precious little time to pursue.
        However, providing the 'nurture' side
        of the nature / nurture equation is a vital role
        that AiWorld seeks to facilitate by paying anyone who can play a
        videogame to help train and create high quality datasets for AI's to
        learn from.
    </p>

    <!--
        Encapsulate moral growth
        Defend humans, the future of humanity, and humane nature.
        Keey humankind ultimately in charge of its own destiny.
    -->
    <h3>The role of emotional intelligence</h3>
    <p>
        <span class="text symbol-grounding">
            Everything we know is built on an innately human experience,
            and fundamental to that experience are our emotions.
            Without emotions, machines will be far less adept at
            learning from the vast knowledge base we have created
            and researchers will be forced to create artificial ways
            for machines to understand humans. [run this by vivian chu georgia tech]
            One can draw a relation to the symbol grounding problem
        </span>
        where it is theorized that words are best understood via a grounding
        in the images, sounds, and other aspects of the human experience
        from which they have been made to abstract.
        <span class="footnote symbol-grounding">
            <a href="http://en.wikipedia.org/wiki/Symbol_grounding"
                >Symbol Grounding</a> - Wikipedia
        </span>
        Similarly, it would be very hard for a computer to answer the
        following question without a solid grounding
        in the human emotional experience:
    </p>
    <blockquote class="text winograd">
        Frank was jealous when Bill said that he was the winner of the
        competition. Who was the winner?
    </blockquote>
    <p>
        For a computer to extract the correct answer
        from just the text would be, if not impossible, extremely difficult
        at this time.
        <span class="footnote winograd">
            Such "Winograd schema questions" are examples of
            frontiers in AI, for many of which solutions are yet undiscovered -
            <a href="http://www.cs.toronto.edu/~hector/Papers/ijcai-13-paper.pdf"
                   >On our best behaviour</a> - Hector Levesque - 2013
        </span>
        However, if we program AI to learn like we do,
        via an embodied and emotional experience - then it
        would not only know the correct answer but it would have a visceral
        understanding of the feeling the answer describes.
        <span class="text deepimagesent">
            Even the amazing results that have been achieved in symbol grounding,
            such as Stanford's DeepImageSent
        </span>
        <span class="footnote deepimagesent">
            <a href="https://cs.stanford.edu/people/karpathy/deepimagesent"
                    >Deep Visual-Semantic Alignments for Generating Image
                Descriptions</a> -
            Andrej Karpathy, Li Fei-Fei - 2014
        </span>
        <span class="text really-far">
            would need human experience and emotion
            to understand the images the way humans do.
        </span>
        <span class="footnote really-far">
          Andrej Karpathy -
          <a href="http://karpathy.github.io/2012/10/22/state-of-computer-vision/"
            >The state of Computer Vision and AI: we are really, really far.</a>
            - 2012
        </span>
        Because without emotions,
        AI will be like a rain man / idiot savant -
        really good at some things, but
        maladjusted in its ability to plugin to our world as a whole.
    </p>
    <p>
        Take the following quote from Yann Lecun, one of the world's preeminent
        AI scientists:
    </p>
    <blockquote class="text yann">
        I think emotions are an integral part of intelligence.
        Science fiction often depicts AI systems as devoid of emotions,
        but I don't think real AI is possible without emotions.
        Emotions are often the result of predicting a likely outcome.
        For example,
        fear comes when we are predicting that something bad (or unknown)
        is going to happen to us. Love is an emotion that evolution built
        into us because we are social animals and we need to reproduce and
        take care of each other. Future AI systems that interact with humans
        will have to have these emotions too.
        <span class="footnote yann">
            Yann Lecun -
            <a href="http://www.reddit.com/r/MachineLearning/comments/25lnbt/ama_yann_lecun/chiftyb"
                    >Reddit AMA</a> - 2014
        </span>
    </blockquote>
    <p>
        <span class="text robot-emotion">
            The only way we know how to create moral beings is the way we
            teach our children and emotions are a fundamental to that.
            Without emotion, we would be inept at judging the values of our actions,
            unable to learn from each other,
            and incapable of maintaining the relationships we rely on to function
            as a society.
        </span>
        <span class="footnote robot-emotion">
            Breazeal, Brooks -
            <a href="http://web.media.mit.edu/~cynthiab/Papers/Breazeal-Brooks-03.pdf"
                >Robot Emotion: A Functional Perspective</a>
            - 2003
        </span>
        Why then should artificial intelligence be devoid
        of emotions? It most certainly should not!
    </p>
    <p>
        One seminal work on the potential of machine intelligence
        came from mathematician and early computing pioneer I. J. Good in
        1965.
    </p>
    <p>
        In it, Good not only first describes the Singularity,
        but is prescient about developments leading to it, saying
    </p>
    <blockquote class="text ij">
        Economy is important in any engineering venture, but especially so
        when the price is exceedingly high, as it most likely will be for the
        first ultraintelligent machine. Hence
        semantics is relevant to the design of such a machine.
        Yet a detailed knowledge of semantics might not be required,
        since the artificial neural network will largely take care of it,
        provided that the parameters are correctly chosen,
        and provided that the network is adequately integrated with
        its sensorium and motorium (input and output).
        For, if these conditions are met,
        the machine will be able to learn from experience, by
        means of positive and negative reinforcement,
        and the instruction of the machine will resemble that of a
        child.
        <span class="footnote ij">
            Irving John Good -
            <a href="http://webdocs.cs.ualberta.ca/~sutton/Good65ultraintelligent.pdf"
                >Speculations Concerning the First Ultraintelligent Machine</a>
            - 1965
        </span>
    </blockquote>
    <p>
        Good amazingly described artificial neural nets,
        reinforcement learning, and feature learning in 1965 -
        long before they rose to prominence in the fields of AI and robotics.
        I believe his last statement describes the idea behind AiWorld.
    <blockquote>
        ...the instruction of the machine will resemble that of a child.
    </blockquote>

    <p>
        A crowdsourced AI training platform
        allows our intelligence, including emotion,
        to be transmitted via interaction with real people as is done
        in our own childhood.
        It provides a decentralized, transparent, and
        iterative way to pursue more sophisticated intelligences, and
        allows us to mold AI in the way we think is best as a society.
    </p>
    <p>
        Let's make AI the vehicle to the future we want for each other, together.
    </p>
    <h2>What can you do?</h2>
    <ul class="call-to-action">
      <li>If you are passionate about working on this, please contact me at craig<span></span>@aiworld.io
      <li><a href="https://vivid-fire-9851.firebaseapp.com/">Help train artificial intelligence</a>
      <li><a href="http://eepurl.com/bcn4Vr">Join the mailing list</a>
      <li>Donate


    </ul>
    <h3>
        Footnotes
    </h3>
    <ol class="footnotes"></ol>
    <h4 class="sig">
        Craig Quiter - 1/4/2015
    </h4>
</div>
<!-- Placed at the end of the document so the pages load faster -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
<script src="vendor/js/bootstrap.min.js"></script>
<script src="vendor/js/docs.js"></script>
<script src="vendor/js/d3.min.js"></script>
<script src="vendor/jquery.qtip.custom/jquery.qtip.min.js"></script>
<script src="assets/js/main.js"></script>
<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
<script src="vendor/js/ie10-viewport-bug-workaround.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-3213633-17', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
